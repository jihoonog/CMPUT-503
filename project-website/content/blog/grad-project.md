---
author: "Jihoon Og"
title: "Grad Final Project"
date: 2023-04-26
description: "CMPUT-503 Grad Project"
tags: ["programming", "ROS", "constrained computing", "tiny ml", "mnist"]
categories: ["robot"]
ShowRelated: false
showToc: true
math: true
ShowBreadCrumbs: false
---

# Grad Final Project

This is my final grad project for CMPUT-503, it's an extension of lab exercise 5 where we used a machine learning model to predict single digit numbers that was trained on MNIST.
For this project I decided to run the model directly on the duckiebot as our previous lab exercise ran the model on a laptop that was getting data from the duckiebot.

## Motivation

In lab exercise 5 we were running a ML model on our laptop as even the smallest ML framework library were too big to fit onto the duckiebot.
However, this communication overhead lead to some performance issues as network congestion lead to poor inference performance and system lag as data packets where being dropped and being forced to re-sent.
Running the model locally on the duckiebot should avoid this overhead as all communication is being done locally on the robot.

## Model Training Pipeline

Installing TensorFlow Lite or any other lightweight ML framework is difficult as the library package is too big to run on the duckiebot itself.
One could implement their own feed-forward and backpropagation module for the the duckiebot but that would be too time consuming and difficult.
Instead, I trained a Multi-Layer Perceptron (MLP) model using Pytorch on a machine with GPU-compute and transferred the weights to the duckiebot to run in inference mode.
This way I only need to implement the inference portion for the duckiebot which for a simple MLP model is trivial to do.

### Model

The model is a relatively simple 4-layer, fully connected model that has 784 inputs from a flatten 28 by 28 gray-scale image with 10 outputs, each representing the prediction strength of a digit.
Between each layer there is a ReLU activation function, and a dropout layer set to 10% to help with over-fitting.

The diagram below shows the model architecture:

![NN model architecture](/uploads/NN-model-arch.png)

### Loss function and Optimizer

Cross-Entropy loss was used as the loss function as this was a classification task on predicting the correct digit or label.
The Pytorch Adam optimizer was used as it showed good convergence performance for training and validation. 

### Dataset

The MNIST training dataset was used to train the model, with a split ratio of 90:10 for training and validation respectively.
The MNIST test dataset was used to verfiy that the model will work however, the actual test number used for the experiment was completely different.

Below is a image of the test number used for the experiment:

![Apriltags numbers](/uploads/grad-project-tags.png)


### Training

The model was trained for 10 epoch and had a test loss of 0.066 and a test accuracy of 97.99%.
The weights that performed the best were exported to the duckiebot for the experiment.


## Video demo

The video below shows our model that is running on the duckiebot in action.

{{< youtube aOkrXP-joYU >}}

- The green bounding box shows the detected region of the post-it note that contains a number.
- The cyan number above the bounding box shows the predicted model generated by the model.
- The yellow time on the right of the predicted number, shows the total time it took the system to predict a number.

## Repo Link

[Grad project repository link](https://github.com/jihoonog/CMPUT-503-Grad-Project)
