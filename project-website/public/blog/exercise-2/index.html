<!doctype html><html lang=en-us><head><meta charset=utf-8><title>Exercise 2 | Piko</title><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Second Lab Assignment"><meta name=author content="Jihoon Og"><link rel=canonical href=https://quackquack.forkprocess.com/blog/exercise-2/><link rel=stylesheet href=https://quackquack.forkprocess.com/sass/main.min.css><link rel=stylesheet href=https://quackquack.forkprocess.com/sass/nav.min.css><link rel=stylesheet href=https://quackquack.forkprocess.com/plugins/css/pico.min.css><script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://quackquack.forkprocess.com/uploads/zap.svg><link rel=icon type=image/png sizes=16x16 href=https://quackquack.forkprocess.com/uploads/zap.svg><link rel=icon type=image/png sizes=32x32 href=https://quackquack.forkprocess.com/uploads/zap.svg><link rel=apple-touch-icon href=https://quackquack.forkprocess.com/uploads/zap.svg><link rel=mask-icon href=https://quackquack.forkprocess.com/uploads/zap.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.92.2"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://quackquack.forkprocess.com/uploads/og.webp"><meta name=twitter:title content="Exercise 2"><meta name=twitter:description content="Second Lab Assignment"><meta property="og:title" content="Exercise 2"><meta property="og:description" content="Second Lab Assignment"><meta property="og:type" content="article"><meta property="og:url" content="https://quackquack.forkprocess.com/blog/exercise-2/"><meta property="og:image" content="https://quackquack.forkprocess.com/uploads/og.webp"><meta property="article:section" content="blog"><meta property="article:published_time" content="2023-02-08T00:00:00+00:00"><meta property="article:modified_time" content="2023-02-08T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://quackquack.forkprocess.com/uploads/og.webp"><meta name=twitter:title content="Exercise 2"><meta name=twitter:description content="Second Lab Assignment"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://quackquack.forkprocess.com/blog/"},{"@type":"ListItem","position":2,"name":"Exercise 2","item":"https://quackquack.forkprocess.com/blog/exercise-2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Exercise 2","name":"Exercise 2","description":"Second Lab Assignment","keywords":["building","programming","ROS","docker","odometry"],"articleBody":"This is the second lab assignment of the course.\nPart 1 ROS Subscriber and Publisher For this exercise were tasked to implement a basic ROS subscriber and publisher that we could use later in the exercise. The ROS framework uses a publish-subscribe architecture to send and receive data (or more specifically messages) to and from different nodes. These messages are transported using topics, these topics are named channels or buffers that publishers can publish messages to while subscribers can subscribe to these topics to listen to the messages. Messages are strongly typed, meaning their schema must be defined during compile time otherwise things will not work. Moreover, topics can only support a single message type, publishing multiple different data types will have all but the last topic type be overwritten by the publisher. However, you can define your own and ROS has a collection of different data types that the end user could use.\nWhile the Duckiebot software stack is based on ROS the robot developers made a custom template repository that one could fork to implement their own ROS package(s) that can be deployed to the Duckiebots. This template repository contains a Dockerfile that is used to download the images, build the container, and run the software programs that is specific to the Duckiebot and the end-user uses it to bootstrap their project.\nFor making our first custom publisher and subscriber we were tasked to grab the video image from the built-in camera and publish it to a custom topic. Following the Duckietown developer guide I created a new python file that will act as my subscriber to the camera’s image topic and publisher to my custom topic. I also added my new file into the launch file so that ROS will know to deploy that file as a new node. Finally, I added the launch file into the launch script that will be used to call roslaunch on the launch file to start my node when the container is running on the robot.\nImage Subscriber To get the image data from the camera I first need to find the topic that contains the data. Running rostopic list gave me the list of all available topics running on the duckiebot. One stood out to me, the /csc22935/camera_node/image/compressed topic seemed most likely to contain the data I need based on its name. Using rqt_image_view and subscribing to that topic confirms my suspicion as I was able to see the images being generated by the camera. Running rostopic info on the topic returned a CompressedImage message type used by the topic. Running rosmsg info on the message type gave me the schema that represented CompressedImage I was only interested in the data itself and thankfully there was an attribute called data that was an array of unsigned bytes, the rest was just metadata. So I created a rospy.Subscriber to listen on the /csc22935/camera_node/image/compressed topic and printing the result out gave me a bunch of random value. Thankfully, this meant that I was getting data from the camera and the garbage mess I was reading was the JPEG encoded data of the image. Now I just needed to publish this to my own custom topic\nImage Publisher Republishing the image data was pretty straightforward. First I needed to create a new CompressedImage variable and do a deep copy of the received data as it is consumed by the subscriber. This new CompressedImage variable also has it header set, so it knows when it was created, and published it to a custom topic. The publisher was created using rospy.Publisher to a custom topic that I called /csc22935/raw_image/compressed, and it uses the same datatype as the subscriber.\nScreenshot of the source code of the image subscriber and publisher Below is a screenshot of the source code of my image subscriber and publisher\n Screenshot of the new image subscriber Below is a screenshot of rqt_image_view showing the image being published to the custom topic\n Odometry In order to know where our robot is within its workspace based on movement alone we first need to know the robot’s odometry. The motors themselves have rotor encoders that counts the number of ticks (or degrees) of rotation that each wheel have rotated. Counting the number of ticks and using a simple equation (see below) allows us to determine how far each wheel has moved laterally.\n$$ \\Delta X = \\frac{2\\cdot\\pi\\cdot R \\cdot N_{ticks}}{N_{total}} $$\nWhere:\n  \\(R\\) is the radius  \\(N_{ticks}\\) is the number of ticks measured  \\(N_{total}\\) is the number of total ticks for a full rotation which in our case is 135.  Now that we can calculate the distance each wheel has traveled we can use transformation matrices to convert them from the robot frame to the world frame and vice versa.\n What is the relation between your initial robot frame and world frame? How do you transform between them?  The initial world frame is 0.32, 0.32 in the x and y coordinates respectively and the theta component is \\(\\dfrac{\\pi}{2}\\) . The robot frame is 0, 0, 0 for the x, y, and theta component respectively. We can convert between the two frames using a forward and reverse kinematics equation. To convert between the world frame to the robot frame we use this equation:\n$$ \\begin{bmatrix}\\dot{x_I}\\\\\\dot{y_I}\\\\\\dot{\\theta_I}\\ \\end{bmatrix} = \\begin{bmatrix}\\cos(\\theta) \u0026 -\\sin(\\theta) \u0026 0\\\\sin(\\theta) \u0026 \\cos(\\theta) \u0026 0\\\\ 0 \u0026 0 \u0026 1\\ \\end{bmatrix} \\begin{bmatrix} \\dot{x_R}\\\\\\dot{y_R}\\\\\\dot{\\theta_R}\\ \\end{bmatrix} + \\begin{bmatrix} 0.32 \\\\ 0.32 \\\\ \\frac{\\pi}{2}\\end{bmatrix} $$\nThe last term is the offset term that is used to account for the different origins between the robot frame and the world frame.\nHow do you convert the location and theta at the initial robot frame to the world frame?  To convert between the robot frame to the world frame we use this equation:\n$$ \\begin{bmatrix}\\dot{x_R}\\\\\\dot{y_R}\\\\\\dot{\\theta_R}\\ \\end{bmatrix} = \\begin{bmatrix}\\cos(\\theta) \u0026 \\sin(\\theta) \u0026 0\\\\ -\\sin(\\theta) \u0026 \\cos(\\theta) \u0026 0\\\\ 0 \u0026 0 \u0026 1\\ \\end{bmatrix} \\begin{bmatrix} \\dot{x_I}\\\\\\dot{y_I}\\\\\\dot{\\theta_I}\\ \\end{bmatrix} - \\begin{bmatrix} 0.32 \\\\ 0.32 \\\\ \\frac{\\pi}{2}\\end{bmatrix} $$\nLikewise in the previous answer, the last term is the offset term that is used to account for the different origins between the robot frame and the world frame.\nCan you explain why there is a difference between actual and desired location?  There could be many factors that could cause an error between the true location and the desired location. Some of these factors could include:\n Wheel slip. Loose tolerances within the encoders. Non-consistent driving surface. No feedback mechanism to check if the motors moved the desired amount. Overshooting and undershooting of the desired target distance.  Which topic(s) did you use to make the robot move? How did you figure out the topic that could make the motor move?  We used the /hostname/wheels_driver_node/wheels_cmd and published WheelsCmdStamped messages to move the left and right motors at a desired velocity. We figured that this topic would move the robot as we looked at the list of all available topics using rostopic list and using intuition guessed that this topic will move the wheels based on the descriptive topic name.\nWhich speed are you using? What happens if you increase/decrease the speed?  We used a value of 0.6 for forward movement and 0.6 for rotational movement. If we increase the speed the robot will move faster but runs the risk of overshooting the desired distance. However, decreasing the speed could prevent the robot from moving as the static friction is greater the motor’s torque.\nHow did you keep track of the angle rotated?  By using the following kinematic equation below:\n$$\\begin{bmatrix}\\dot{x}_R \\\\\\dot{y}_R \\\\\\dot{\\theta}_R \\\\ \\end{bmatrix} = \\begin{bmatrix} \\frac{r\\dot{\\varphi}_r}{2} + \\frac{r\\dot{\\varphi}_l}{2} \\\\ 0 \\\\ \\frac{r\\dot{\\varphi}_r}{2\\cdot l} - \\frac{r\\dot{\\varphi}_l}{2\\cdot l} \\\\ \\end{bmatrix}$$\nWe can find the change of the robot’s directional pose based on the left and right wheels' linear distance change.\nWhich topic(s) did you use to make the robot rotate?  We used the same topic to rotate the robot as to move the robot forward.\nHow did you estimate/track the angles your duckieBot has traveled?  Using the equation listed from the previous answer for question 6. We added all the changes of the robot’s angle to the initial angle the robot started with throughout the whole execution of the robot’s movement.\nWhile we can implement these equations into the motor control node that is used to estimate the robot’s pose and correct for drift. We would much rather use the Duckietown’s implementation [1] for the Duckiebot as it is more likely to be correct and robust compared to our implementation. For example, in their implementation they use AppromixateTime to synchronize the timestamp between the two encoder messages so that the message from one encoder is close to the timestamp of the other. The code reference is linked below.\nPart 2 In this part we are tasked to create a multi-state program where our robot will move about in the lab’s Duckietown environment following a pre-programed route and setting the LED light pattern to indicate the robot’s current state.\nArchitecture Below is the ROS computation graph for implementing this exercise. It is comprised with two nodes:\n The state_control_node is responsible for maintaining the current state of the robot as well as its state transitions and setting the LED patterns. It also give commands to the motor_control_node to move the robot to a specified location in world frame. The motor_control_node is responsible for moving the robot to a specific location based on commands received from state_control_node. It handles all odometry calculations, dead reckoning, error corrections, and motor control for the robot. Once the current command is successfully completed an acknowledgement is sent back to the state_control_node indicating that the robot finished the current task.   The State Control Node The state control node as stated before is responsible for maintaining the current state, state transition, and setting of the LEDs for the robot. In our implementation states are executed in a sequential fashion. Once a command in published to the motor_control_node the state_control_node is blocked until it receives a confirmation that the command was successfully completed. This confirmation comes from the motor_control_node. Once the confirmation message is received it can then move onto publishing the next command to the motor_control_node. The commands themselves are fairly simple, due to the simple tasks that our robot needed to do. The commands are a formatted string that is published to the motor_control_node using a String type message. An example command could be \"forward:2.3\" meaning move forward 2.3 meters from the current world frame. Another could be \"right:80\" meaning rotate right (clockwise) 80 degrees. Parsing is done at the motor_control_node.\nLED light pattern For setting the light patterns for different stages of the task, we first run this command to launch the led_emitter_node:\ndts duckiebot demo --demo_name led_emitter_node --duckiebot_name $BOT --package_name led_emitter --image duckietown/dt-core:daffy-arm64v8 We then use the service /led_emitter_node/set_custom_pattern to set the different LED patterns to their corresponding state. Since we need to call this service multiple times, we keep the connection persistent.\nThe colour pattern for each state is defined below:\n Red Blue Green Purple  The Motor Control Node The motor control node as stated before is responsible for all movement command executions, odometry calculations, dead reckoning, error corrections, and motor control for the robot. The motor_control_node is more of a listener to the state_control_node, it doesn’t do anything until it receives a command from the controller that is the state_control_node. Once it receives a command it then executes that command to the best of it’s ability. There are three functions that implement the movements required for the lab exercise. One moves the robot forward by a specified amount in meters one rotates the robot by a specified amount in degrees, and one moves the robot in an arcing motion that is kinda hacky.\nCommands received are appended to a list where it is used to update and correct the robot’s pose. It also provides a useful debugging tool to see any errors in the robot’s odometry. For forward movement there is a vector that connects the robot’s pre-movement position to its target position. The robot then follows that vector to the target position. For rotational movement the robot will rotate in place until the robot’s theta odometry is close to the target’s direction. The rotation in-place is done by having one motor spin in one direction and the other motor spin in the other direction at the same speed so that there isn’t any translational movement during rotation. For the arc movement one of the motor is spinning faster than the other so that it can create both a translational and rotational movement.\nCorrections Due to manufacturing defects, loose tolerances, the unpredictable nature of reality, and the fact that we can’t assume a spherical duck. There will be some error or drift between the target pose and the actual pose. In this exercise we were not required to implement close-loop control but I found it easier to implement some kind of control loop feedback that made it easier to do all the required tasks without driving off Duckietown. There are many process variables (PV) that we could have use to have our robot drive in a straight line:\n The difference in distances each wheel has traveled The drift between the target track and the robot’s position to that track  But the one that works best for us, was the angle between the robot vector and the target vector. The diagram below shows a visual representation of the two vectors.\n   \\(\\vec{R}\\) is the robot vector which describes where the robot is heading. This is derived from the robot’s odometry.  \\(\\vec{T}\\) is the target vector which describes the heading to the target position from the robot’s position.  Minimizing the angle between the robot vector and the target vector while driving forward should get our robot to the desired location. To get the angle between the robot vector and the target vector we can use the dot product divided by the product magnitude of the two vectors to get the cosine value where taking the inverse gives us the angle.\n$$ \\frac{\\vec{R} \\cdot \\vec{T}}{||\\vec{R} || \\cdot || \\vec{T}||} = \\cos(\\theta) \\rightarrow \\arccos(\\cos(\\theta)) = \\theta $$\nHowever, this does not gives us the direction on where the target vector lies in relation to the robot vector. For that we need the cross product of the two vectors to find the sin value that will gives the direction. If the value is less than 0 then the target is right of the robot, if greater than 0 then the target is left of the robot.\n$$ \\frac{\\vec{R}\\times\\vec{T}}{||\\vec{R} || \\cdot || \\vec{T}|| \\cdot u} = \\sin(\\theta) $$\nNow that we have the magnitude and direction of the error we can add this into our close-loop feedback system which in this case is PID control.\nPID Control A PID (proportional-integral-derivative) controller is a commonly used feedback control-loop mechanism that gives corrections to a process or a plant such that its output or process value matches the desired set-point [2]. It uses three tunable parameters that takes into account the present error, past errors, and an estimate of future errors to provide a correction value such that it minimizes over-corrective oscillation and unnecessary delay. The equation below is the overall control function:\n$$ u(t) = K_pe(t) + K_i \\int_0^te(\\tau) d\\tau + K_d\\frac{de(t)}{dt} $$\nWhere:\n  \\(K_p\\) is the proportional gain, a tuning parameter,  \\(K_i\\) is the integral gain, a tuning parameter,  \\(K_d\\) is the derivative gain, a tuning parameter,  \\(e(t)\\) is the error between the set-point or target point and process variable at time \\(t\\) ,  \\(t\\) is the time,  \\(\\tau\\) is the variable of integration (takes on values from time 0 to the present \\(t\\) ).  Now tuning these parameters could be a course all in itself and I had a limited amount of time so I guessed and checked by tuning each parameter separately and settled on the parameters listed below:\n  \\(K_p = 0.4\\)   \\(K_i = 0.075\\)   \\(K_d = 0.0\\)   We used someone elses PID controller [3] for implementing PID control.\n What is the final location of your robot as shown in your odometry reading?  The final location of the robot is: 0.39, 0.53, ~86.7 degrees for x, y, and theta respectively\n Is it close to your robot’s actual physical location in the mat world frame?  Using Euclidean distance the difference was 22.14 centimeters.\nVideo The video below shows the robot performing some basic pre-planned maneuvers in Duckietown:\n  The video below shows the robot’s odometry over time while performing the same basic pre-planned maneuvers from the video above:\n  ROS Bag Bag file\nRepo Link Exercise 2 repository link\nReferences This is a list of references that I used to do this exercise.\n Deadreckoning: https://github.com/duckietown/dt-core/blob/daffy/packages/deadreckoning/src/deadreckoning_node.py PID Controller: https://en.wikipedia.org/wiki/PID_controller PID controller code: https://github.com/jellevos/simple-ros-pid/blob/master/simple_pid/PID.py  ","wordCount":"2780","inLanguage":"en","datePublished":"2023-02-08T00:00:00Z","dateModified":"2023-02-08T00:00:00Z","author":{"@type":"Person","name":"Jihoon Og"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://quackquack.forkprocess.com/blog/exercise-2/"},"publisher":{"@type":"Organization","name":"Piko","logo":{"@type":"ImageObject","url":"https://quackquack.forkprocess.com/uploads/zap.svg"}}}</script></head><body><nav class=desktop><ul><li><a class=logo href=https://quackquack.forkprocess.com/ accesskey=h title="Welcome to my CMPUT-503 course project's website (Alt + h)"><img src=/uploads/zap.svg alt="Welcome to my CMPUT-503 course project's website" width=35 height=35></img><h3 style=margin-bottom:0><strong><em>CMPUT-503 Robotics Project</em></strong></h3></a></li><li class=toggle-container><input type=checkbox id=switch>
<label for=switch><i id=darkIcon data-feather=moon></i>
<i id=lightIcon data-feather=sun></i></label></li></ul><ul class=desktop-navigation><li><a href=/blog title=Blog><i data-feather=pen-tool></i>
<span>Blog</span></a></li><li><a href=/search title="Search (Alt + /)" accesskey=/><i data-feather=search></i>
<span>Search</span></a></li><li><a href=https://github.com/jihoonog/CMPUT-503 title=Github><i data-feather=github></i>
<span></span></a></li></ul><ul class=mobile-navigation><li><button id=menuOpen onclick=openMobile() aria-label="Menu closed">
<i data-feather=menu></i></button>
<button id=menuClose onclick=openMobile() aria-label="Menu opened">
<i data-feather=x></i></button></li></ul></nav><aside class=sidebar id=mobileNav style=display:none><nav><ul><li><a href=/blog title=Blog><span><i data-feather=pen-tool></i>
Blog</span></a></li><li><a href=/search title="Search (Alt + /)" accesskey=/><span><i data-feather=search></i>
Search</span></a></li><li><a href=https://github.com/jihoonog/CMPUT-503 title=Github><span><i data-feather=github></i></span></a></li></ul></nav></aside><main><div class=container><hgroup><h1>Exercise 2</h1><time datetime="2023-02-08 00:00:00 +0000 UTC">February 8, 2023</time>&nbsp;·&nbsp;14 min&nbsp;·&nbsp;Jihoon Og<p>Second Lab Assignment</p></hgroup><a href=https://quackquack.forkprocess.com/tags/building/><kbd>building</kbd></a>
<a href=https://quackquack.forkprocess.com/tags/programming/><kbd>programming</kbd></a>
<a href=https://quackquack.forkprocess.com/tags/ros/><kbd>ROS</kbd></a>
<a href=https://quackquack.forkprocess.com/tags/docker/><kbd>docker</kbd></a>
<a href=https://quackquack.forkprocess.com/tags/odometry/><kbd>odometry</kbd></a><div class="grid grid-main"><div><article class=toc><div><details><summary accesskey=c title="(Alt + C)"><span>Table of Contents</span></summary><div><ul><li><a href=#part-1 aria-label="Part 1">Part 1</a><ul><li><a href=#ros-subscriber-and-publisher aria-label="ROS Subscriber and Publisher">ROS Subscriber and Publisher</a><ul><li><a href=#image-subscriber aria-label="Image Subscriber">Image Subscriber</a></li><li><a href=#image-publisher aria-label="Image Publisher">Image Publisher</a></li><li><a href=#screenshot-of-the-source-code-of-the-image-subscriber-and-publisher aria-label="Screenshot of the source code of the image subscriber and publisher">Screenshot of the source code of the image subscriber and publisher</a></li><li><a href=#screenshot-of-the-new-image-subscriber aria-label="Screenshot of the new image subscriber">Screenshot of the new image subscriber</a></li></ul></li><li><a href=#odometry aria-label=Odometry>Odometry</a></li></ul></li><li><a href=#part-2 aria-label="Part 2">Part 2</a><ul><li><a href=#architecture aria-label=Architecture>Architecture</a><ul><li><a href=#the-state-control-node aria-label="The State Control Node">The State Control Node</a><ul><li><a href=#led-light-pattern aria-label="LED light pattern">LED light pattern</a></li></ul></li><li><a href=#the-motor-control-node aria-label="The Motor Control Node">The Motor Control Node</a><ul><li><a href=#corrections aria-label=Corrections>Corrections</a></li><li><a href=#pid-control aria-label="PID Control">PID Control</a></li></ul></li></ul></li><li><a href=#video aria-label=Video>Video</a></li><li><a href=#ros-bag aria-label="ROS Bag">ROS Bag</a></li></ul></li><li><a href=#repo-link aria-label="Repo Link">Repo Link</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div></article><div class=post><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on twitter" href="https://twitter.com/intent/tweet/?text=Exercise%202&url=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f&hashtags=building%2cprogramming%2cROS%2cdocker%2codometry"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f&title=Exercise%202&summary=Exercise%202&source=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f&title=Exercise%202"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on whatsapp" href="https://api.whatsapp.com/send?text=Exercise%202%20-%20https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on telegram" href="https://telegram.me/share/url?text=Exercise%202&url=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div><p>This is the second lab assignment of the course.</p><h1 id=part-1>Part 1<a class=anchor aria-hidden=true href=#part-1>#</a></h1><h2 id=ros-subscriber-and-publisher>ROS Subscriber and Publisher<a class=anchor aria-hidden=true href=#ros-subscriber-and-publisher>#</a></h2><p>For this exercise were tasked to implement a basic ROS subscriber and publisher that we could use later in the exercise.
The ROS framework uses a publish-subscribe architecture to send and receive data (or more specifically messages) to and from different nodes. These messages are transported using <code>topics</code>, these topics are named channels or buffers that publishers can publish messages to while subscribers can subscribe to these topics to listen to the messages. Messages are strongly typed, meaning their schema must be defined during compile time otherwise things will not work. Moreover, topics can only support a single message type, publishing multiple different data types will have all but the last topic type be overwritten by the publisher. However, you can define your own and ROS has a collection of different data types that the end user could use.</p><p>While the Duckiebot software stack is based on ROS the robot developers made a custom template repository that one could fork to implement their own ROS package(s) that can be deployed to the Duckiebots. This template repository contains a Dockerfile that is used to download the images, build the container, and run the software programs that is specific to the Duckiebot and the end-user uses it to bootstrap their project.</p><p>For making our first custom publisher and subscriber we were tasked to grab the video image from the built-in camera and publish it to a custom topic. Following the Duckietown developer guide I created a new python file that will act as my subscriber to the camera&rsquo;s image topic and publisher to my custom topic. I also added my new file into the launch file so that ROS will know to deploy that file as a new node. Finally, I added the launch file into the launch script that will be used to call <code>roslaunch</code> on the launch file to start my node when the container is running on the robot.</p><h3 id=image-subscriber>Image Subscriber<a class=anchor aria-hidden=true href=#image-subscriber>#</a></h3><p>To get the image data from the camera I first need to find the topic that contains the data.
Running <code>rostopic list</code> gave me the list of all available topics running on the duckiebot.
One stood out to me, the <code>/csc22935/camera_node/image/compressed</code> topic seemed most likely to contain the data I need based on its name. Using <code>rqt_image_view</code> and subscribing to that topic confirms my suspicion as I was able to see the images being generated by the camera.
Running <code>rostopic info</code> on the topic returned a <code>CompressedImage</code> message type used by the topic.
Running <code>rosmsg info</code> on the message type gave me the schema that represented <code>CompressedImage</code> I was only interested in the data itself and thankfully there was an attribute called <code>data</code> that was an array of unsigned bytes, the rest was just metadata.
So I created a <code>rospy.Subscriber</code> to listen on the <code>/csc22935/camera_node/image/compressed</code> topic and printing the result out gave me a bunch of random value.
Thankfully, this meant that I was getting data from the camera and the garbage mess I was reading was the JPEG encoded data of the image.
Now I just needed to publish this to my own custom topic</p><h3 id=image-publisher>Image Publisher<a class=anchor aria-hidden=true href=#image-publisher>#</a></h3><p>Republishing the image data was pretty straightforward. First I needed to create a new <code>CompressedImage</code> variable and do a deep copy of the received data as it is consumed by the subscriber. This new <code>CompressedImage</code> variable also has it header set, so it knows when it was created, and published it to a custom topic.
The publisher was created using <code>rospy.Publisher</code> to a custom topic that I called <code>/csc22935/raw_image/compressed</code>, and it uses the same datatype as the subscriber.</p><h3 id=screenshot-of-the-source-code-of-the-image-subscriber-and-publisher>Screenshot of the source code of the image subscriber and publisher<a class=anchor aria-hidden=true href=#screenshot-of-the-source-code-of-the-image-subscriber-and-publisher>#</a></h3><p>Below is a screenshot of the source code of my image subscriber and publisher</p><p><img src=/uploads/new_subpub_node.png alt="image sub code"></p><h3 id=screenshot-of-the-new-image-subscriber>Screenshot of the new image subscriber<a class=anchor aria-hidden=true href=#screenshot-of-the-new-image-subscriber>#</a></h3><p>Below is a screenshot of <code>rqt_image_view</code> showing the image being published to the custom topic</p><p><img src=/uploads/new_node_rqt_image_view.png alt="image sub"></p><h2 id=odometry>Odometry<a class=anchor aria-hidden=true href=#odometry>#</a></h2><p>In order to know where our robot is within its workspace based on movement alone we first need to know the robot&rsquo;s odometry. The motors themselves have rotor encoders that counts the number of ticks (or degrees) of rotation that each wheel have rotated. Counting the number of ticks and using a simple equation (see below) allows us to determine how far each wheel has moved laterally.</p><p>$$
\Delta X = \frac{2\cdot\pi\cdot R \cdot N_{ticks}}{N_{total}}
$$</p><p>Where:</p><ul><li>\(R\)
is the radius</li><li>\(N_{ticks}\)
is the number of ticks measured</li><li>\(N_{total}\)
is the number of total ticks for a full rotation which in our case is 135.</li></ul><p>Now that we can calculate the distance each wheel has traveled we can use transformation matrices to convert them from the robot frame to the world frame and vice versa.</p><ol><li>What is the relation between your initial robot frame and world frame? How do you transform between them?</li></ol><p>The initial world frame is 0.32, 0.32 in the x and y coordinates respectively and the theta component is
\(\dfrac{\pi}{2}\)
.
The robot frame is 0, 0, 0 for the x, y, and theta component respectively.
We can convert between the two frames using a forward and reverse kinematics equation.
To convert between the world frame to the robot frame we use this equation:</p><p>$$
\begin{bmatrix}\dot{x_I}\\\dot{y_I}\\\dot{\theta_I}\ \end{bmatrix} = \begin{bmatrix}\cos(\theta) & -\sin(\theta) & 0\\sin(\theta) & \cos(\theta) & 0\\ 0 & 0 & 1\ \end{bmatrix} \begin{bmatrix} \dot{x_R}\\\dot{y_R}\\\dot{\theta_R}\ \end{bmatrix} + \begin{bmatrix} 0.32 \\ 0.32 \\ \frac{\pi}{2}\end{bmatrix}
$$</p><p>The last term is the offset term that is used to account for the different origins between the robot frame and the world frame.</p><ol start=2><li>How do you convert the location and theta at the initial robot frame to the world frame?</li></ol><p>To convert between the robot frame to the world frame we use this equation:</p><p>$$
\begin{bmatrix}\dot{x_R}\\\dot{y_R}\\\dot{\theta_R}\ \end{bmatrix} = \begin{bmatrix}\cos(\theta) & \sin(\theta) & 0\\ -\sin(\theta) & \cos(\theta) & 0\\ 0 & 0 & 1\ \end{bmatrix} \begin{bmatrix} \dot{x_I}\\\dot{y_I}\\\dot{\theta_I}\ \end{bmatrix} -
\begin{bmatrix} 0.32 \\ 0.32 \\ \frac{\pi}{2}\end{bmatrix}
$$</p><p>Likewise in the previous answer, the last term is the offset term that is used to account for the different origins between the robot frame and the world frame.</p><ol start=3><li>Can you explain why there is a difference between actual and desired location?</li></ol><p>There could be many factors that could cause an error between the true location and the desired location. Some of these factors could include:</p><ul><li>Wheel slip.</li><li>Loose tolerances within the encoders.</li><li>Non-consistent driving surface.</li><li>No feedback mechanism to check if the motors moved the desired amount.</li><li>Overshooting and undershooting of the desired target distance.</li></ul><ol start=4><li>Which topic(s) did you use to make the robot move? How did you figure out the topic that could make the motor move?</li></ol><p>We used the <code>/hostname/wheels_driver_node/wheels_cmd</code> and published <code>WheelsCmdStamped</code> messages to move the left and right motors at a desired velocity. We figured that this topic would move the robot as we looked at the list of all available topics using <code>rostopic list</code> and using intuition guessed that this topic will move the wheels based on the descriptive topic name.</p><ol start=5><li>Which speed are you using? What happens if you increase/decrease the speed?</li></ol><p>We used a value of <code>0.6</code> for forward movement and <code>0.6</code> for rotational movement. If we increase the speed the robot will move faster but runs the risk of overshooting the desired distance. However, decreasing the speed could prevent the robot from moving as the static friction is greater the motor&rsquo;s torque.</p><ol start=6><li>How did you keep track of the angle rotated?</li></ol><p>By using the following kinematic equation below:</p><p>$$\begin{bmatrix}\dot{x}_R \\\dot{y}_R \\\dot{\theta}_R \\ \end{bmatrix} = \begin{bmatrix} \frac{r\dot{\varphi}_r}{2} + \frac{r\dot{\varphi}_l}{2} \\ 0 \\ \frac{r\dot{\varphi}_r}{2\cdot l} - \frac{r\dot{\varphi}_l}{2\cdot l} \\ \end{bmatrix}$$</p><p>We can find the change of the robot&rsquo;s directional pose based on the left and right wheels' linear distance change.</p><ol start=7><li>Which topic(s) did you use to make the robot rotate?</li></ol><p>We used the same topic to rotate the robot as to move the robot forward.</p><ol start=8><li>How did you estimate/track the angles your duckieBot has traveled?</li></ol><p>Using the equation listed from the previous answer for question 6. We added all the changes of the robot&rsquo;s angle to the initial angle the robot started with throughout the whole execution of the robot&rsquo;s movement.</p><p>While we can implement these equations into the motor control node that is used to estimate the robot&rsquo;s pose and correct for drift. We would much rather use the Duckietown&rsquo;s implementation [1] for the Duckiebot as it is more likely to be correct and robust compared to our implementation. For example, in their implementation they use <code>AppromixateTime</code> to synchronize the timestamp between the two encoder messages so that the message from one encoder is close to the timestamp of the other. The code reference is linked below.</p><h1 id=part-2>Part 2<a class=anchor aria-hidden=true href=#part-2>#</a></h1><p>In this part we are tasked to create a multi-state program where our robot will move about in the lab&rsquo;s Duckietown environment following a pre-programed route and setting the LED light pattern to indicate the robot&rsquo;s current state.</p><h2 id=architecture>Architecture<a class=anchor aria-hidden=true href=#architecture>#</a></h2><p>Below is the ROS computation graph for implementing this exercise.
It is comprised with two nodes:</p><ul><li>The <strong>state_control_node</strong> is responsible for maintaining the current state of the robot as well as its state transitions and setting the LED patterns. It also give commands to the <code>motor_control_node</code> to move the robot to a specified location in world frame.</li><li>The <strong>motor_control_node</strong> is responsible for moving the robot to a specific location based on commands received from <code>state_control_node</code>. It handles all odometry calculations, dead reckoning, error corrections, and motor control for the robot. Once the current command is successfully completed an acknowledgement is sent back to the <code>state_control_node</code> indicating that the robot finished the current task.</li></ul><p><img src=/uploads/CMPUT-503-ROS-Node-setup.svg alt="ROS node setup"></p><h3 id=the-state-control-node>The State Control Node<a class=anchor aria-hidden=true href=#the-state-control-node>#</a></h3><p>The state control node as stated before is responsible for maintaining the current state, state transition, and setting of the LEDs for the robot.
In our implementation states are executed in a sequential fashion.
Once a command in published to the <code>motor_control_node</code> the <code>state_control_node</code> is blocked until it receives a confirmation that the command was successfully completed. This confirmation comes from the <code>motor_control_node</code>.
Once the confirmation message is received it can then move onto publishing the next command to the <code>motor_control_node</code>.
The commands themselves are fairly simple, due to the simple tasks that our robot needed to do.
The commands are a formatted string that is published to the <code>motor_control_node</code> using a String type message.
An example command could be <code>"forward:2.3"</code> meaning move forward 2.3 meters from the current world frame.
Another could be <code>"right:80"</code> meaning rotate right (clockwise) 80 degrees.
Parsing is done at the <code>motor_control_node</code>.</p><h4 id=led-light-pattern>LED light pattern<a class=anchor aria-hidden=true href=#led-light-pattern>#</a></h4><p>For setting the light patterns for different stages of the task, we first run this command to launch the <code>led_emitter_node</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>dts duckiebot demo --demo_name led_emitter_node --duckiebot_name $BOT --package_name led_emitter --image duckietown/dt-core:daffy-arm64v8
</code></pre></div><p>We then use the service <code>&lt;VEHICLE_NAME>/led_emitter_node/set_custom_pattern</code> to set the different LED patterns to their corresponding state.
Since we need to call this service multiple times, we keep the connection persistent.</p><p>The colour pattern for each state is defined below:</p><ol><li>Red</li><li>Blue</li><li>Green</li><li>Purple</li></ol><h3 id=the-motor-control-node>The Motor Control Node<a class=anchor aria-hidden=true href=#the-motor-control-node>#</a></h3><p>The motor control node as stated before is responsible for all movement command executions, odometry calculations, dead reckoning, error corrections, and motor control for the robot.
The <code>motor_control_node</code> is more of a listener to the <code>state_control_node</code>, it doesn&rsquo;t do anything until it receives a command from the controller that is the <code>state_control_node</code>. Once it receives a command it then executes that command to the best of it&rsquo;s ability.
There are three functions that implement the movements required for the lab exercise.
One moves the robot forward by a specified amount in meters one rotates the robot by a specified amount in degrees, and one moves the robot in an arcing motion that is kinda hacky.</p><p>Commands received are appended to a list where it is used to update and correct the robot&rsquo;s pose.
It also provides a useful debugging tool to see any errors in the robot&rsquo;s odometry.
For forward movement there is a vector that connects the robot&rsquo;s pre-movement position to its target position.
The robot then follows that vector to the target position.
For rotational movement the robot will rotate in place until the robot&rsquo;s theta odometry is close to the target&rsquo;s direction. The rotation in-place is done by having one motor spin in one direction and the other motor spin in the other direction at the same speed so that there isn&rsquo;t any translational movement during rotation.
For the arc movement one of the motor is spinning faster than the other so that it can create both a translational and rotational movement.</p><h4 id=corrections>Corrections<a class=anchor aria-hidden=true href=#corrections>#</a></h4><p>Due to manufacturing defects, loose tolerances, the unpredictable nature of reality, and the fact that we can&rsquo;t assume a spherical duck.
There will be some error or drift between the target pose and the actual pose.
In this exercise we were not required to implement close-loop control but I found it easier to implement some kind of control loop feedback that made it easier to do all the required tasks without driving off Duckietown.
There are many process variables (PV) that we could have use to have our robot drive in a straight line:</p><ul><li>The difference in distances each wheel has traveled</li><li>The drift between the target track and the robot&rsquo;s position to that track</li></ul><p>But the one that works best for us, was the angle between the robot vector and the target vector.
The diagram below shows a visual representation of the two vectors.</p><p><img src=/uploads/diagram-20230208.svg alt="robot vector diagram"></p><ul><li>\(\vec{R}\)
is the robot vector which describes where the robot is heading. This is derived from the robot&rsquo;s odometry.</li><li>\(\vec{T}\)
is the target vector which describes the heading to the target position from the robot&rsquo;s position.</li></ul><p>Minimizing the angle between the robot vector and the target vector while driving forward should get our robot to the desired location.
To get the angle between the robot vector and the target vector we can use the dot product divided by the product magnitude of the two vectors to get the cosine value where taking the inverse gives us the angle.</p><p>$$
\frac{\vec{R} \cdot \vec{T}}{||\vec{R} || \cdot || \vec{T}||} = \cos(\theta) \rightarrow \arccos(\cos(\theta)) = \theta
$$</p><p>However, this does not gives us the direction on where the target vector lies in relation to the robot vector.
For that we need the cross product of the two vectors to find the sin value that will gives the direction.
If the value is less than 0 then the target is right of the robot, if greater than 0 then the target is left of the robot.</p><p>$$
\frac{\vec{R}\times\vec{T}}{||\vec{R} || \cdot || \vec{T}|| \cdot u} = \sin(\theta)
$$</p><p>Now that we have the magnitude and direction of the error we can add this into our close-loop feedback system which in this case is PID control.</p><h4 id=pid-control>PID Control<a class=anchor aria-hidden=true href=#pid-control>#</a></h4><p>A PID (proportional-integral-derivative) controller is a commonly used feedback control-loop mechanism that gives corrections to a process or a plant such that its output or process value matches the desired set-point [2].
It uses three tunable parameters that takes into account the present error, past errors, and an estimate of future errors to provide a correction value such that it minimizes over-corrective oscillation and unnecessary delay.
The equation below is the overall control function:</p><p>$$
u(t) = K_pe(t) + K_i \int_0^te(\tau) d\tau + K_d\frac{de(t)}{dt}
$$</p><p>Where:</p><ul><li>\(K_p\)
is the proportional gain, a tuning parameter,</li><li>\(K_i\)
is the integral gain, a tuning parameter,</li><li>\(K_d\)
is the derivative gain, a tuning parameter,</li><li>\(e(t)\)
is the error between the set-point or target point and process variable at time
\(t\)
,</li><li>\(t\)
is the time,</li><li>\(\tau\)
is the variable of integration (takes on values from time 0 to the present
\(t\)
).</li></ul><p>Now tuning these parameters could be a course all in itself and I had a limited amount of time so I guessed and checked by tuning each parameter separately and settled on the parameters listed below:</p><ul><li>\(K_p = 0.4\)</li><li>\(K_i = 0.075\)</li><li>\(K_d = 0.0\)</li></ul><p>We used someone elses PID controller [3] for implementing PID control.</p><ol><li>What is the final location of your robot as shown in your odometry reading?</li></ol><p>The final location of the robot is: 0.39, 0.53, ~86.7 degrees for x, y, and theta respectively</p><ol><li>Is it close to your robot’s actual physical location in the mat world frame?</li></ol><p>Using Euclidean distance the difference was 22.14 centimeters.</p><h2 id=video>Video<a class=anchor aria-hidden=true href=#video>#</a></h2><p>The video below shows the robot performing some basic pre-planned maneuvers in Duckietown:</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/-8USVB2A9jE style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p>The video below shows the robot&rsquo;s odometry over time while performing the same basic pre-planned maneuvers from the video above:</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/fucIoBTw888 style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h2 id=ros-bag>ROS Bag<a class=anchor aria-hidden=true href=#ros-bag>#</a></h2><p><a href=https://github.com/jihoonog/CMPUT-503-Exercise-2/raw/v2/bags/final.bag target=_blank rel=noopener>Bag file</a></p><h1 id=repo-link>Repo Link<a class=anchor aria-hidden=true href=#repo-link>#</a></h1><p><a href=https://github.com/jihoonog/CMPUT-503-Exercise-2/tree/561e08a558a95b95e2c01dd21c2394f2f9b4fb34 target=_blank rel=noopener>Exercise 2 repository link</a></p><h1 id=references>References<a class=anchor aria-hidden=true href=#references>#</a></h1><p>This is a list of references that I used to do this exercise.</p><ol><li>Deadreckoning: <a href=https://github.com/duckietown/dt-core/blob/daffy/packages/deadreckoning/src/deadreckoning_node.py target=_blank rel=noopener>https://github.com/duckietown/dt-core/blob/daffy/packages/deadreckoning/src/deadreckoning_node.py</a></li><li>PID Controller: <a href=https://en.wikipedia.org/wiki/PID_controller target=_blank rel=noopener>https://en.wikipedia.org/wiki/PID_controller</a></li><li>PID controller code: <a href=https://github.com/jellevos/simple-ros-pid/blob/master/simple_pid/PID.py target=_blank rel=noopener>https://github.com/jellevos/simple-ros-pid/blob/master/simple_pid/PID.py</a></li></ol></div><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on twitter" href="https://twitter.com/intent/tweet/?text=Exercise%202&url=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f&hashtags=building%2cprogramming%2cROS%2cdocker%2codometry"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f&title=Exercise%202&summary=Exercise%202&source=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f&title=Exercise%202"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on whatsapp" href="https://api.whatsapp.com/send?text=Exercise%202%20-%20https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Exercise 2 on telegram" href="https://telegram.me/share/url?text=Exercise%202&url=https%3a%2f%2fquackquack.forkprocess.com%2fblog%2fexercise-2%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></div></div></div></main><footer class=text-center><span>A template by <a href=https://www.heksagon.net title="Your most friendly developer">Heksagon</a> &copy; 2023 Piko</span><div><a href=https://quackquack.forkprocess.com/legal/privacy>Privacy Policy</a>
<span>&</span>
<a href=https://quackquack.forkprocess.com/legal/terms-and-conditions>Terms and Conditions</a></div></footer><article class=hidden id=cookie-banner><div><span>We use cookies to improve your experience on our site and to show you relevant advertising.</span></div><footer><a role=button id=consent-cookies>Close</a>
<a role=button class=secondary href=/legal/privacy/#cookies-and-web-beacons>Cookies Policy</a></footer></article><script async src=https://quackquack.forkprocess.com/js/cookie.min.js layout=container></script>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('kbd');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script><script src=https://quackquack.forkprocess.com/plugins/js/feather.min.js layout=container></script>
<script src=https://quackquack.forkprocess.com/js/script.min.js layout=container></script></body></html>